{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection for NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the more advanced task of parameter selection for NMF topic modelling - namely, selecting a useful value for the number of topics *k*.\n",
    "\n",
    "Note that this notebook requires v4 of the [Gensim package](https://radimrehurek.com/gensim) to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, joblib\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "import gensim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# settings for our plots later\n",
    "plt.style.use(\"ggplot\")\n",
    "matplotlib.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the TF-IDF normalised document-term matrix and list of terms that we stored earlier using *Joblib*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A,terms,snippets) = joblib.load(\"articles-tfidf.pkl\")\n",
    "print(\"Loaded %d X %d document-term matrix\" % (A.shape[0], A.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach for parameter selection is to Measure and compare the topic coherence of models generated for different values of *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to start by pre-specifying an initial range of \"sensible\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin, kmax = 4, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMF for each of these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_models = []\n",
    "# try each value of k\n",
    "for k in range(kmin,kmax+1):\n",
    "    print(\"Applying NMF for k=%d ...\" % k )\n",
    "    # run NMF\n",
    "    model = decomposition.NMF( init=\"nndsvd\", n_components=k ) \n",
    "    W = model.fit_transform( A )\n",
    "    H = model.components_    \n",
    "    # store for later\n",
    "    topic_models.append( (k,W,H) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the number of topics, here we will use a *topic coherence* measure called TC-W2V. This measure relies on the use of a *word embedding* model constructed from our corpus. So in this step we will use the *Gensim* implementation of Word2Vec to build a Word2Vec model based on our collection of news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you want to skip this step, a pre-built Word2Vec model for the sample dataset [is also provided here for download](http://erdos.ucd.ie/files/pydata/w2v-model.bin) (71MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the documents from the input file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(\"data\") / \"articles.txt\"\n",
    "raw_documents = []\n",
    "with open(in_path, \"r\") as fin:\n",
    "    # each line is a document\n",
    "    for line in fin.readlines():\n",
    "        raw_documents.append(line.strip().lower())\n",
    "print(\"Read %d raw text documents\" % len(raw_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the custom stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = []\n",
    "with open(\"stopwords.txt\", \"r\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        custom_stop_words.append(line.strip().lower())\n",
    "# note that we need to make it hashable\n",
    "print(\"Stopword list has %d entries\" % len(custom_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define a class that will generate documents in a form that can be consumed by Gensim's Word2Vec implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenGenerator:\n",
    "    def __init__(self, documents, stopwords):\n",
    "        self.documents = documents\n",
    "        self.stopwords = stopwords\n",
    "        self.tokenizer = re.compile( r\"(?u)\\b\\w\\w+\\b\" )\n",
    "\n",
    "    def __iter__(self):\n",
    "        print(\"Building Word2Vec model ...\")\n",
    "        for doc in self.documents:\n",
    "            tokens = []\n",
    "            for tok in self.tokenizer.findall( doc ):\n",
    "                if tok in self.stopwords:\n",
    "                    tokens.append( \"<stopword>\" )\n",
    "                elif len(tok) >= 2:\n",
    "                    tokens.append( tok )\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a Skipgram Word2Vec model from all documents in the input file using *Gensim*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docgen = TokenGenerator(raw_documents, custom_stop_words)\n",
    "# the model has 500 dimensions, the minimum document-term frequency is 20\n",
    "w2v_model = gensim.models.Word2Vec(docgen, vector_size=500, min_count=20, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model has %d terms\" % len(w2v_model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for later use, so that we do not need to rebuild it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"w2v-model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To re-load this model, run\n",
    "#w2v_model = gensim.models.Word2Vec.load(\"w2v-model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once we have our Word2vec model, we can use it as part of our *topic coherence* approach to evaluate the different NMF topic models that we created previously. To do this, we will implement a simple version of the TC-W2V coherence measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Word2vec model to calculate coherence scores for each of these models. We will define this coherence score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coherence(w2v_model, term_rankings):\n",
    "    overall_coherence = 0.0\n",
    "    for topic_index in range(len(term_rankings)):\n",
    "        # check each pair of terms\n",
    "        pair_scores = []\n",
    "        for pair in combinations( term_rankings[topic_index], 2 ):\n",
    "            pair_scores.append( w2v_model.wv.similarity(pair[0], pair[1]) )\n",
    "        # get the mean for all pairs in this topic\n",
    "        topic_score = sum(pair_scores) / len(pair_scores)\n",
    "        overall_coherence += topic_score\n",
    "    # get the mean score across all topics\n",
    "    return overall_coherence / len(term_rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a function to get the topic descriptor (i.e. list of top terms) for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor( all_terms, H, topic_index, top ):\n",
    "    # reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
    "    # now get the terms corresponding to the top-ranked indices\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append( all_terms[term_index] )\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now process each of the models for different values of *k*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = []\n",
    "coherences = []\n",
    "for (k,W,H) in topic_models:\n",
    "    # Get all of the topic descriptors - the term_rankings, based on top 10 terms\n",
    "    term_rankings = []\n",
    "    for topic_index in range(k):\n",
    "        term_rankings.append( get_descriptor( terms, H, topic_index, 10 ) )\n",
    "    # Now calculate the coherence based on our Word2vec model\n",
    "    k_values.append( k )\n",
    "    coherences.append( calculate_coherence( w2v_model, term_rankings ) )\n",
    "    print(\"K=%02d: Coherence=%.4f\" % ( k, coherences[-1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use *matplotlib* to generate a line plot of these coherence scores, to help us select an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,7))\n",
    "# create the line plot\n",
    "ax = plt.plot( k_values, coherences )\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Mean Coherence\")\n",
    "# add the points\n",
    "plt.scatter(k_values, coherences, s=120)\n",
    "# find and annotate the maximum point on the plot\n",
    "ymax = max(coherences)\n",
    "xpos = coherences.index(ymax)\n",
    "best_k = k_values[xpos]\n",
    "plt.annotate(\"k=%d\" % best_k, xy=(best_k, ymax), xytext=(best_k, ymax), textcoords=\"offset points\", fontsize=16)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Final  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above suggests that the most appropriate value for the number of topics is *k=8*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = best_k\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[k-kmin][1]\n",
    "H = topic_models[k-kmin][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the topic descriptors for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor(terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join(descriptor)\n",
    "    print(\"Topic %02d: %s\" % (topic_index+1, str_descriptor) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3dd349d56abd7701b2e4d88ab44696293e44ecedbdcf133fcb5722b3cee9765"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
